<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on LightEnglishr</title>
    <link>/post/</link>
    <description>Recent content in Posts on LightEnglishr</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Wed, 08 Feb 2023 00:00:00 +0000</lastBuildDate><atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>现实中的“三体”真的能够被发现吗</title>
      <link>https://hidadeng.github.io/post/2023-02-08-et/</link>
      <pubDate>Wed, 08 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-08-et/</guid>
      <description>description用于SEO优化</description>
      <content:encoded><![CDATA[<h2 id="寻找外星人的想法越来越有创意">寻找外星人的想法越来越有创意</h2>
<p>Jan 18th 2023 The Economist</p>
<p>​       人类一直未停止寻找外星人，其中最著名的 SETI 计划，是唯一由官方牵头，寻找外星人的计划。</p>
<p>​       文章指出：墨西哥州的Very Large Array (VLA)射电天文台将开始将其所有收集到的数据发送给cosmic，这是一个专门用于搜寻外星生物智慧的计算机集群。自去年 12 月以来，南非的Meerkat天文台也使用了类似的系统。在接下来的两年中，VLA单独将对 4 千万星星进行观察。计算机还将从以前的射电和可见光频率调查中挖掘数据，寻找任何不属于地球的不自然物。如果银河系中有许多高度发达的文明，并发出强烈的信号，这可能是一种正确的方法。</p>
<br>
<h2 id="视频讲解">视频讲解</h2>
<iframe
    src="//player.bilibili.com/player.html?bvid=BV1Hv4y147xe&page=1"
    scrolling="no"
    height="500px"
    width="800px"
    frameborder="no"
    framespacing="0"
    allowfullscreen="true"
>
</iframe>

<h2 id="原文">原文</h2>
<p>This month the vla (Very Large Array) radio-astronomy observatory in New Mexico will begin sending every bit of data it harvests for astronomers’ research projects to cosmic, a computer cluster dedicated to the search for extraterrestrial intelligence (seti). A similar system has been piggybacking on the Meerkat observatory in South Africa (pictured) since December.</p>
<p>Over the next two years, the vla alone will cast an eye over 40m stars. Computers will also be mining data from past surveys, in radio frequencies and in visible light, for anything that seems both unnatural and not from Earth, says James Davenport, an astronomer at the University of Washington who works with such surveys.</p>
<p>If there are many technologically advanced civilisations in the galaxy, emitting powerful signals, this might well be the right approach, according to Steve Croft of the University of California, Berkeley. Some of them will then be where users of the vla happen to be looking. Either that, or they will be close enough to be detectable from existing survey data.</p>
<p>But if extraterrestrial civilisations are rare, and thus mostly far away, or if they rarely broadcast with a lot of power, they will be found only by selecting promising sources in advance and staring at them for a long time. This is done by the Green Bank Telescope, a large radio dish in West Virginia, for which the Berkeley seti Research Centre has contracted 20% of the observing time, with Dr Croft as project scientist.</p>
<p>Dr Davenport and Dr Croft were both addressing a session on detecting extraterrestrial intelligences at a meeting of the American Astronomical Society, held in Seattle from January 8th-12th. This is a field that goes in and out of fashion, but at the moment fortune is smiling on it in the form of the Breakthrough Listen project, paid for by Yuri Milner, a Silicon Valley venture capitalist.</p>
<p>Breakthrough Listen, which began in 2016, is scheduled to last for ten years, and will disburse $100m over that period. The money is paying for observations by the Green Bank Telescope, Meerkat, the Parkes radio observatory in Australia and the Automated Planet Finder telescope at the Lick Observatory in California.</p>
<p>A question preoccupying Dr Croft is how to select Green Bank’s targets. One answer is to try to get inside et’s head (or equivalent brain-containing part of the anatomy). Starting from the assumption (admittedly generous) that there are beings out there who actively wish to talk to their galactic neighbours, how would they go about it?</p>
<p>As luck would have it, one obvious approach does et-seekers’ work for them. A good way to discover planets orbiting other stars is by looking for transits—brief diminutions in the light from a star caused by a planet passing in front of it, as seen from Earth. So far 3,941 planets orbiting other stars have been discovered that way. This method would also be obvious to extraterrestrial intelligences, and it would make sense for them to concentrate their broadcasts on planets they have discovered. For Earthbound seekers after aliens, this means they have to orient their antennas towards the Earth Transit Zone, a band across the sky from which Earth could be seen to transit the sun. Directing his telescope at planets known of in that zone would be a good gambit for Dr Croft.</p>
<p>Another suggestion is that garrulous ets might use supernovae to flag transmissions. That, Dr Davenport explained, might work like this. An extraterrestrial intelligence which wanted to make itself known would broadcast high-power signals of its existence every time its astronomers observed a supernova—and then wait.</p>
<p>What happens next is a complicated geometrical dance. Two wavefronts of electromagnetic radiation—one from the supernova and one from the et—are now spreading through space at the speed of light. For most potential listeners, they would arrive at different times, depending on their location with respect to both.</p>
<p><strong>Galactic semaphore</strong></p>
<p>It would make no sense for those seeking their galactic neighbours to start listening precisely when they saw a supernova, for they would not know where to look for any signal that might have been sent in response to it. But what such listeners, including those on Earth, could do, is go back to their archives and choose a supernova they saw in the past, say 1,000 years ago. The next step would be to see if there are any stars for which the time the supernova signal would take to travel there, plus the time for the broadcast it may have triggered to travel to Earth, would add up to 1,000 years as well. Those would be the stars from which signals could potentially be arriving at that moment.</p>
<p>As he told the meeting, Andy Nilipour of Yale University has been doing just this for supernovae described in 1054 by Chinese astronomers, in 1572 by Tycho Brahe, in 1604 by Johannes Kepler and in 1987 by many, many astronomers. Using data from Gaia, an orbiting observatory belonging to the European Space Agency, he is able to measure the locations of many stars with a precision of a few light-years. He has found 465 that fit the bill.</p>
<p>Such a level of precision is available, though, only for stars that are fairly close by. A complementary approach, proposed recently by Seto Naoki of Kyoto University, overcomes that by looking not at stars a certain distance from a supernova, but in a certain direction relative to it.</p>
<p>This would, Dr Seto outlined in a paper he published in 2021, work somewhat like a rugby player passing the ball to another who is running at full tilt. At any given time, there is a special direction to throw the ball, so that it will arrive while moving at right angles to the direction of the receiving player. In a similar way, you can at any particular moment find a special direction for two planets and a supernova. With luck, both parties will know to look in that direction to make contact. Mr Nilipour has also found 403 stars for which this approach would work, for a total of 868 between the two methods.</p>
<p>These approaches do, though, depend on et wishing to be found. Other civilisations may be shy, or simply not care. It may nevertheless be possible to discover where they are hiding.</p>
<p>In 2013, Andrew Siemion, who now works at the seti Institute, a non-profit organisation that has been active in the alien-searching business since 1984, proposed looking for systems where planets not only transit their star as viewed from Earth, but also regularly occult each other, which means two of them line up precisely in the direction of Earth. If both were inhabited by members of the same intelligent species, one having been settled from the other, they would presumably be in communication. That would require fairly powerful signals—and in this case they would be aimed in exactly the right direction to travel onward to Earth.</p>
<p>Evan Sneed of the University of California, Riverside, Sofia Sheikh of the seti Institute, and Nick Tusay of Penn State University are now doing the calculations for 60 promising systems where transits happen, to work out a calendar for observing them. So far, they have looked at seven.</p>
<p>Mr Tusay also told the conference about his search for extraterrestrial probes in the solar system. That such things exist is an even longer shot than looking for radio signals from afar. But that, in the view of seti enthusiasts, is not a reason not to try.</p>
<p>The question is, where to scout around? In principle, such probes could be anywhere. But there are places where they might be especially useful to their owners. These are where the sun’s gravity would concentrate light or radio waves from particular nearby star systems. It is easy to calculate that any signal from, say, Alpha Centauri, would be enhanced along a line pointing away from the sun in opposition to that star system, starting 550 times as far from the sun as Earth is.</p>
<p>That Alpha Centauri or any other nearby star system is home to an et is the longest of long shots. But, doubling down on what such civilisations might be capable of, Mr Tusay suggests probes like this might be relay stations, passing signals on to others in communication with other systems. This would make the solar system a node in a galactic internet of sorts.</p>
<p>Such probes might also exchange signals with counterparts in the centre of the solar system, closer to Earth, keeping an eye on what was happening there. That means those signals might be detectable.</p>
<p>Mr Tusay looked for such signals with the Green Bank Telescope, but found none. However, in the grand tradition of seti research, the motto of which seems to be “never give up”, this has not made him discard the idea just yet. Probes like this might communicate in ways no one has looked at or even thought of, or maybe they happened to be silent when the observations were done.</p>
<p><strong>Spiders, but not from Mars</strong></p>
<p>Carmen Choza of the Berkeley seti Research Centre, meanwhile, presented the results of a so-far fruitless search for beacons not in nearby star systems in the Milky Way, Earth’s home galaxy, but in 97 others. To be detectable from such distances any radio broadcasts would have had to be unbelievably powerful—and so presumably produced by civilisations that can harness the power of whole stars.</p>
<p>An intelligent species with such energy requirements would have a hard time hiding, if it even cared to. It might even become what Clément Vidal, a philosopher, calls a stellivore civilisation. Tapping the power of entire stars would require engineering on a grand scale. Dr Nilipour plans to look in this context at a special kind of star system called a spider pulsar.</p>
<p>Spider pulsars are thought to be neutron stars with a low-mass ordinary star orbiting so close that it is being destroyed by the neutron star’s emissions. Mr Nilipour wants to see if there is anything going on here that might not be quite natural.</p>
<p>His first step will be to spot stars in the growing Gaia catalogue which are on their way to having a close encounter with a spider pulsar. Anything about their relative motion that would require the influence of more than regular gravity would suggest a stellivore preparing to tuck into its next meal. He has already found some semi-promising candidates—in particular, some stars that may fall victim to such attention in 10,000 years or so.</p>
<p>There is no spider pulsar near Earth, fortunately. But such ideas, wild as they are, do raise the question of whether human beings should do more than just listen for signs of et. Talking, albeit with a time delay of decades or even centuries, with other intelligent species would be exhilarating. But if it involved organisms with that sort of power, it might also be pretty dangerous.</p>
<h2 id="雅思词汇">雅思词汇</h2>
<table>
<thead>
<tr>
<th>单词</th>
<th>音标</th>
<th>中文释义</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>radio-astronomy</strong></td>
<td>ˌreɪdɪoʊəˈstrɑːnəmi</td>
<td>无线电天文学</td>
</tr>
<tr>
<td><strong>observatory</strong></td>
<td>əbˈzɜːrvətɔːri</td>
<td>观测站</td>
</tr>
<tr>
<td><strong>harvests</strong></td>
<td>ˈhɑːrvɪsts</td>
<td>收获</td>
</tr>
<tr>
<td><strong>astronomers</strong></td>
<td>əˈstrɑːnəmərs</td>
<td>天文学家</td>
</tr>
<tr>
<td><strong>research projects</strong></td>
<td>ˈriːsɜːrtʃ prəˈdʒekts</td>
<td>研究项目</td>
</tr>
<tr>
<td><strong>cosmic</strong></td>
<td>ˈkɑːzmɪk</td>
<td>宇宙的</td>
</tr>
<tr>
<td><strong>computer cluster</strong></td>
<td>kəmˈpjuːtər klʌstər</td>
<td>计算机集群</td>
</tr>
<tr>
<td><strong>extraterrestrial</strong></td>
<td>ˌɛkstrətəˈrɛstriəl</td>
<td>外星的</td>
</tr>
<tr>
<td><strong>intelligence</strong></td>
<td>ɪnˈtɛlɪdʒəns</td>
<td>智能</td>
</tr>
<tr>
<td><strong>Meerkat</strong></td>
<td>ˈmɪrkæt</td>
<td>豹猫</td>
</tr>
<tr>
<td><strong>piggybacking</strong></td>
<td>ˈpɪɡibækɪŋ</td>
<td>搭便车</td>
</tr>
<tr>
<td><strong>visible light</strong></td>
<td>ˈvɪzəbl laɪt</td>
<td>可见光</td>
</tr>
<tr>
<td><strong>frequencies</strong></td>
<td>ˈfriːkwənsiz</td>
<td>频率</td>
</tr>
<tr>
<td><strong>unnatural</strong></td>
<td>ʌnˈnætʃərəl</td>
<td>非自然的</td>
</tr>
<tr>
<td><strong>Green Bank Telescope</strong></td>
<td>ˈɡriːn bæŋk ˈteləskəʊp</td>
<td>绿银望远镜</td>
</tr>
<tr>
<td><strong>radio dish</strong></td>
<td>ˈreɪdɪoʊ dɪʃ</td>
<td>无线电盘</td>
</tr>
</tbody>
</table>
<br>
<h2 id="资料获取">资料获取</h2>
<p><a href="%E5%AF%BB%E6%89%BE%E5%A4%96%E6%98%9F%E4%BA%BA%E7%9A%84%E6%83%B3%E6%B3%95%E8%B6%8A%E6%9D%A5%E8%B6%8A%E6%9C%89%E5%88%9B%E6%84%8F.pdf">点击下载文本pdf学习资料</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>让元宇宙体验感UP的触觉手套真的能够实现吗</title>
      <link>https://hidadeng.github.io/post/2023-02-06-the-metaverse/</link>
      <pubDate>Mon, 06 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-06-the-metaverse/</guid>
      <description>在计算机游戏和虚拟现实领域，触觉学家们正试图在视觉和听觉的基础上增加触觉，以增强虚拟世界的浸入感。</description>
      <content:encoded><![CDATA[<h2 id="元宇宙和未来小工具的敏感世界">元宇宙和未来小工具的敏感世界</h2>
<p>The Economist Feb 1st 2023</p>
<p>​       <strong>元宇宙</strong>（英语：metaverse）是一个聚焦于社交连结的3D[虚拟世界]之网络。此虚拟环境将可以通过[虚拟现实眼镜]、[扩增实境]眼镜、手机、[个人电脑]和[电子游戏机]进入人造的虚拟世界。</p>
<p>​       文章讲述了触觉的发展。在计算机游戏和虚拟现实领域，触觉学家们正试图在视觉和听觉的基础上增加触觉，以增强虚拟世界的浸入感。未来，用户将通过穿着触觉衣服来体验这一切，包括触觉手套和触觉背心等，以便在虚拟世界中感知触觉。不同公司使用不同的技术，如电气刺激、振动马达和压缩空气等。触觉技术的初始市场主要是企业，如医学学校和工程师协作等。未来，这种技术也有可能用于普通消费者。</p>
<br>
<h2 id="视频讲解">视频讲解</h2>
<iframe
    src="//player.bilibili.com/player.html?bvid=BV12x4y1571A&page=1"
    scrolling="no"
    height="500px"
    width="800px"
    frameborder="no"
    framespacing="0"
    allowfullscreen="true"
>
</iframe>

<br>
<br>
<h2 id="原文">原文</h2>
<p>以下是<strong>原文</strong>以及<strong>雅思词汇解析</strong>：</p>
<p>The brave new world Aldous Huxley describes in his novel of that title features the “feelies”. In 1932, its year of publication, movies were turning into talkies. Feelies must have seemed a logical, if creepy, extension of that. The book alludes to a film at a local theatre with a love scene on a bearskin rug, in which the sensation of every hair of the bear is reproduced.</p>
<p><img loading="lazy" src="feelies.jpg" alt="img"  />
</p>
<p>The feelies have still not arrived. But people are working on them. In computer games and virtual reality (vr), two heirs to cinema’s role in light entertainment, practitioners of the discipline of haptics are attempting to add a sense of touch to those of vision and hearing, to <a href="https://www.economist.com/science-and-technology/2023/02/01/researchers-find-a-way-to-make-vr-headsets-more-realistic">increase the illusion of immersion in a virtual world</a>. In future, they hope, if you reach out to pluck an apple from a tree in such a paradise, your hand will no longer go through it. You will, rather, be able to feel and grasp the fruit, if not actually eat it. Conversely, if it is a paradise lost you are in, and a baddy hiding behind the apple tree shoots you, you will feel the bullet’s impact.</p>
<p>To experience all this a user will wear haptic clothing. The ambitious talk of whole-body haptic suits, but in the case of the apple, the tree and the gunman haptic gloves and a haptic vest would suffice. Moving a gloved hand creates corresponding movement of a user’s virtual hand, with sensations appropriate to objects “touched” being fed back via devices called haptic actuators, incorporated into the glove. Haptic vests similarly stimulate parts of the upper body.</p>
<p><strong>Hand in glove</strong></p>
<p>Actuators themselves come in a variety of forms. Those most widely used at the moment are erms (eccentric rotating masses) and lras (linear resonant actuators). An erm is a tiny motor that drives a shaft fitted with an off-centre weight which causes the whole thing to vibrate when the shaft spins. An lra uses an electromagnetic coil to shake a surface. Nowadays, these devices are employed for jobs like alerting smartphone users to incoming messages and reacting when a touchscreen is tapped. But adapting such well-understood technologies for use in vr and gaming should be fairly easy.</p>
<p>erms and lrass are not, however, the only possible approaches to immersive haptics. For instance, owo Game, a Spanish firm, is about to put on sale a haptic vest, worn next to the skin, that relies on electrical stimulation rather than vibrating actuators. It delivers tuneable levels of current to different parts of the torso. Besides creating tingling sensations, these can also cause muscles to contract. Effects replicable using this approach apparently include being shot, stabbed and blown up.</p>
<p>In Redmond, Washington, meanwhile, a firm called HaptX has reached for pneumatics, a technology many might think had seen its heyday. Bob Crockett, one of the company’s founders, explains that the firm needs compressed air to produce a big enough displacement of the skin to effect a realistic sensation of touch. Other haptic devices, he says, cannot do that.</p>
<p>HaptX’s gloves, branded g1, have their air pumped in and out through a network of tubes which inflate or deflate 135 tiny balloons incorporated into each glove. The most sensitive of these balloons—those in the finger tips—are less than 1mm in diameter. The gloves’ fingers also include pneumatic “exotendons”, which brake the fingers’ movement, thereby simulating the feeling of touching a solid object. The compressor and electronics powering the system are held in a backpack, so a user can move around freely.</p>
<p>None of this will be cheap. A pair of g1 gloves will set you back at least $4,500. The initial market, though, is corporate, rather than retail. Early customers are expected to include organisations that already use vr for training and want to improve the experience: medical schools teaching operating techniques to surgeons, for example, or workshops that repair jet engines. Another use might be to permit collaboration between engineers living in different parts of the world. People working on a new car, say, could meet in a virtual laboratory, tinker with virtual components, and pass around virtual copies of their designs.</p>
<p>There is, though, a further reason why HaptX has chosen pneumatics: it does not intend to stop at making gloves. It has plans for a whole-body haptic suit and thinks pneumatic actuation will be easier to scale up than something based on electric motors. It is cagey about details, but users would don an exoskeleton that could create sensations all over the body—including forces that pull a user’s hands downward, so he or she would feel the weight of virtual objects.</p>
<p><strong>Unvested interest</strong></p>
<p>vr and gaming are the high end of haptics. But ways of improving haptic feedback in the non-virtual world are important, too. Smartphones, computers and the touchscreens now proliferating in vehicles, fast-food venues and so on could all benefit from a bit of haptic feedback.</p>
<p>Aito, a firm based in Amsterdam, hopes to provide just that. It produces haptic systems for laptops and other digital devices. These employ actuators based on piezoelectric materials, which shrink or expand in response to a voltage, producing a slight movement. And the process works in reverse, as well. When squeezed, a piezoelectric crystal generates a current. This means piezo materials can be employed both as actuators and as sensors.</p>
<p>Aito’s actu-sensors have three layers. Their covers are plastic, glass or even wood. Below lies a capacitance grid, which determines, from the change created in the grid’s electric field, the position of a finger touching the device. The third layer is a matrix of piezo activators. All three combine into something barely 1.8mm thick that can be incorporated into touchscreens and touch pads.</p>
<p>When an actu-sensor detects a finger it responds appropriately, according to the position and pressure of the digit in question. It might create clicks. Or rumbles. Or form the screen’s upper layer into a stable but scratchy surface that would cause a finger or a plastic stylus to feel like a fountain pen gliding over paper, or like a brush painting on canvas.</p>
<p>With the introduction of portable devices that have foldable screens, the lower half might thereby be used as a haptic keyboard. It could be programmed to provide a tactile response like that of a mechanical keyboard, but with additional features, says Nedko Ivanov, Aito’s boss. For instance, pressing down harder would capitalise a letter, doing away with the need for a shift key.</p>
<p>This would also allow devices to be slimmer and lighter. And the same machine could be sold in different places without having to modify its hardware, for a screen-based haptic keyboard could be programmed to use whatever character set was appropriate to the local language.</p>
<p>Some of these new features will work their way into cars, too—especially as conventional dashboard switches are replaced more and more by icons on a screen. Without a satisfying mechanical click, it can be hard to tell, without taking your eyes off the road, whether such icons have been activated or deactivated.</p>
<p>And there is also one other potentially big use for haptics. Pornographers were early pioneers of the internet (and, indeed, of film and photography before that). So it is hardly surprising a number of them are now working on virtual-sex encounters—known in the trade as “teledildonics”. Some companies producing sex toys, for example, have already begun adding Bluetooth-enabled items to their range, allowing couples to link up remotely, as it were. Perhaps Huxley wasn’t so far off the money after all.</p>
<br>
<h2 id="雅思词汇">雅思词汇</h2>
<table>
<thead>
<tr>
<th>雅思词汇</th>
<th>音标</th>
<th>中文释义</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>feelies</strong></td>
<td>[ˈfiːliːz]</td>
<td>感觉电影</td>
</tr>
<tr>
<td><strong>alludes</strong></td>
<td>[əˈluːdz]</td>
<td>暗示</td>
</tr>
<tr>
<td><strong>theatre</strong></td>
<td>[ˈθɪətə(r)]</td>
<td>剧院</td>
</tr>
<tr>
<td><strong>sensation</strong></td>
<td>[senˈseɪʃən]</td>
<td>感觉</td>
</tr>
<tr>
<td><strong>reproduced</strong></td>
<td>[ˌriːprəˈduːst]</td>
<td>复制</td>
</tr>
<tr>
<td><strong>virtual reality</strong></td>
<td>[ˈvɜːtʃuəl rɪˈæləti]</td>
<td>虚拟现实</td>
</tr>
<tr>
<td><strong>heirs</strong></td>
<td>[ˈherz]</td>
<td>继承人</td>
</tr>
<tr>
<td><strong>light entertainment</strong></td>
<td>[ˈlaɪt ˈentəˈteɪnmənt]</td>
<td>轻松娱乐</td>
</tr>
<tr>
<td><strong>haptics</strong></td>
<td>[ˈhæptɪks]</td>
<td>触觉学</td>
</tr>
<tr>
<td><strong>immersion</strong></td>
<td>[ɪˈmɜːʃən]</td>
<td>沉浸</td>
</tr>
<tr>
<td><strong>grasp</strong></td>
<td>[ɡræsp]</td>
<td>抓住</td>
</tr>
<tr>
<td><strong>baddy</strong></td>
<td>[ˈbædi]</td>
<td>坏人</td>
</tr>
<tr>
<td><strong>bullet&rsquo;s impact</strong></td>
<td>[ˈbʊlɪts ˈɪmpækt]</td>
<td>子弹的冲击</td>
</tr>
<tr>
<td><strong>haptic clothing</strong></td>
<td>[ˈhæptɪk ˈkloʊðɪŋ]</td>
<td>触觉服装</td>
</tr>
<tr>
<td><strong>whole-body haptic suits</strong></td>
<td>[ˈhoʊlˈbɑːdi ˈhæptɪk ˈsuːts]</td>
<td>整体触觉套装</td>
</tr>
<tr>
<td><strong>haptic gloves</strong></td>
<td>[ˈhæptɪk ɡlɑːvz]</td>
<td>触觉手套</td>
</tr>
<tr>
<td><strong>haptic vest</strong></td>
<td>[ˈhæptɪk vest]</td>
<td>触觉背心</td>
</tr>
<tr>
<td><strong>haptic actuators</strong></td>
<td>[ˈhæptɪk ˈæktjʊˈeɪtərz]</td>
<td>触觉执行器</td>
</tr>
<tr>
<td><strong>linear resonant actuators</strong></td>
<td>[ˈlɪnɪər ˈrezənənt ˈæktjʊˈeɪtərz]</td>
<td>线性共振驱动器</td>
</tr>
</tbody>
</table>
<br>
<h2 id="资料获取">资料获取</h2>
<p><a href="%E5%85%83%E5%AE%87%E5%AE%99%E5%92%8C%E6%9C%AA%E6%9D%A5%E5%B0%8F%E5%B7%A5%E5%85%B7%E7%9A%84%E6%95%8F%E6%84%9F%E4%B8%96%E7%95%8C.pdf">点击下载本文pdf学习资料</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>10个你需要学英语的理由</title>
      <link>https://hidadeng.github.io/post/2023-02-02-why-we-should-learn-english/</link>
      <pubDate>Thu, 02 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-02-why-we-should-learn-english/</guid>
      <description>description用于SEO优化</description>
      <content:encoded><![CDATA[<h2 id="理由有">理由有</h2>
<ol>
<li>人类社会最流行的语言</li>
<li>增加求职竞争力，更容易找工作</li>
<li>53个国家官方语言</li>
<li>全球4亿人的第一语言</li>
<li>媒体产业的语言</li>
<li>IT领域首选工作语言</li>
<li>26个简单的阿拉伯字符</li>
<li>可以学到各种新技术</li>
<li>有助于接触和学习世界文化</li>
<li>&hellip;.</li>
</ol>
<br>
<h2 id="reanson-1-人类社会最流行的语言">Reanson-1 人类社会最流行的语言</h2>
<br> 
<h2 id="reanson-2-人类社会最流行的语言">Reanson-2 人类社会最流行的语言</h2>
<br> 
## Reanson-3 增加求职竞争力，更容易找工作
<br> 
<h2 id="reanson-4-53个国家官方语言">Reanson-4 53个国家官方语言</h2>
<br> 
<h2 id="reanson-5-全球4亿人的第一语言">Reanson-5 全球4亿人的第一语言</h2>
<br> 
<h2 id="reanson-6-媒体产业的语言">Reanson-6 媒体产业的语言</h2>
<br> 
<h2 id="reanson-7-it领域首选工作语言">Reanson-7 IT领域首选工作语言</h2>
<br> 
<h2 id="reanson-8-26个简单的阿拉伯字符">Reanson-8 26个简单的阿拉伯字符</h2>
<br> 
<h2 id="reanson-9-可以学到各种新技术">Reanson-9 可以学到各种新技术</h2>
<br> 
<h2 id="reanson-10-有助于接触和学习世界文化">Reanson-10 有助于接触和学习世界文化</h2>
<br> 
]]></content:encoded>
    </item>
    
    <item>
      <title>markdown使用教程</title>
      <link>https://hidadeng.github.io/post/2023-02-02-markdown-tutorial/</link>
      <pubDate>Thu, 02 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-02-markdown-tutorial/</guid>
      <description>markdown使用教程</description>
      <content:encoded><![CDATA[<h2 id="markdown简介">markdown简介</h2>
<p>简单好用啊</p>
<br>
<h2 id="安装">安装</h2>
<br>
<h2 id="语法">语法</h2>
<br>
<h2 id="功能">功能</h2>
<ul>
<li>N级标题</li>
<li>粗体</li>
<li>引用</li>
<li>列表
<ul>
<li>无序列表</li>
<li>有序列表</li>
</ul>
</li>
<li>表格</li>
<li>插入图片</li>
<li>插入链接</li>
</ul>
<br>
<h2 id="n级标题">N级标题</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">### 三级标题
</span></span></code></pre></div><h3 id="三级标题">三级标题</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">#### 四级标题
</span></span></code></pre></div><h4 id="四级标题">四级标题</h4>
<br>
<h2 id="粗体">粗体</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">你好，**Hugo**博客
</span></span></code></pre></div><p>你好，<strong>Hugo</strong>博客</p>
<br>
<h2 id="列表">列表</h2>
<h3 id="有序列表">有序列表</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">1. 第一个
</span></span><span class="line"><span class="cl">2. 第二个
</span></span><span class="line"><span class="cl">3. 第三个
</span></span></code></pre></div><ol>
<li>第一个</li>
<li>第二个</li>
<li>第三个</li>
</ol>
<br>
<h3 id="无序列表">无序列表</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">- 元素1
</span></span><span class="line"><span class="cl">- 元素2
</span></span><span class="line"><span class="cl">- 元素3
</span></span></code></pre></div><ul>
<li>元素1</li>
<li>元素2</li>
<li>元素3</li>
</ul>
<br>
<h2 id="链接">链接</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">[大邓和他的python](https://hidadeng.github.io/)
</span></span></code></pre></div><p><a href="https://hidadeng.github.io/">大邓和他的python</a></p>
<br>
<h2 id="插入图片">插入图片</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">![](http://localhost:4321/images/blog/markdown-cover.png)
</span></span><span class="line"><span class="cl">![](http://localhost:4321/images/blog/markdown-cover.png)
</span></span></code></pre></div><p><img loading="lazy" src="http://localhost:4321/images/blog/markdown-cover.png" alt=""  />
</p>
<br>
<h2 id="插入b站视频">插入b站视频</h2>
<p><a href="https://www.bilibili.com/video/BV1vA4y197YR/">https://www.bilibili.com/video/BV1vA4y197YR/</a></p>
<p><img loading="lazy" src="img/bilibili.png" alt=""  />
</p>
<iframe
    src="//player.bilibili.com/player.html?bvid=BV1vA4y197YR&page=1"
    scrolling="no"
    height="500px"
    width="800px"
    frameborder="no"
    framespacing="0"
    allowfullscreen="true"
>
</iframe>

]]></content:encoded>
    </item>
    
    <item>
      <title>商务英语是什么学科</title>
      <link>https://hidadeng.github.io/post/2023-02-02-what-is-business-english/</link>
      <pubDate>Thu, 02 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-02-what-is-business-english/</guid>
      <description>商务英语是什么学科</description>
      <content:encoded><![CDATA[<p><img loading="lazy" src="img/test.png" alt=""  />
</p>
<h2 id="一背景">一、背景</h2>
<p>ssss</p>
<br>
<h2 id="二商务英语学什么">二、商务英语学什么</h2>
<h3 id="21">2.1</h3>
<h3 id="22">2.2</h3>
<h3 id="23">2.3</h3>
<h2 id="三-就业">三、 就业</h2>
<p>ssss</p>
<br>
<h2 id="资料下载">资料下载</h2>
<p><a href="%E8%AF%BE%E6%97%B6%E4%BA%8C%E7%AE%80%E5%8D%95%E5%8F%A5.pdf">点击下载本文的pdf资料</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>谁将撼动Chatgpt的地位，AI聊天机器人的未来发展如何 </title>
      <link>https://hidadeng.github.io/post/2023-02-02-who-will-challenge-the-position-of-chatgpt/</link>
      <pubDate>Thu, 02 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>/post/2023-02-02-who-will-challenge-the-position-of-chatgpt/</guid>
      <description>OpenAI 的人工智能聊天机器人 Chatgpt 在 11 月推出后五天内吸引了100万用户，是历史上消费产品推出最快的之一。刚刚投资 10 亿美元的微软希望 Chatgpt 的能力，包括生成似乎是由人类创建的文本、图像和视频，可以注入许多软件销售。1 月 26 日，谷歌发布了一篇论文，描述了一种类似的模型，可以从歌曲的文字描述中创建音乐。它的母公司 Alphabet 的投资者正在寻找其对 Chatgpt 的回答。据报道，中国的搜索巨头百度计划在 3 月加入聊天机器人。此外，各种公司研究实验室也在竞争人工智能的优势，其中一些是大型科技公司的一部分，一些与他们有关，一些是独立的创业公司。全球各大公司和独立创业公司都在激烈竞争 AI 的优势，而这场竞赛的结果将决定 AI 的时代对于电脑用户的到来以及谁将占领市场。</description>
      <content:encoded><![CDATA[<h2 id="人工智能实验室的竞赛升温">人工智能实验室的竞赛升温</h2>
<p>The Economist Jan 30th 2023</p>
<p>近期人工智能领域迎来新热潮，The Economist 的一篇文章对该现象进行了分析。</p>
<p>文章指出： OpenAI 的人工智能聊天机器人 Chatgpt 在 11 月推出后五天内吸引了100万用户，是历史上消费产品推出最快的之一。刚刚投资 10 亿美元的微软希望 Chatgpt 的能力，包括生成似乎是由人类创建的文本、图像和视频，可以注入许多软件销售。1 月 26 日，谷歌发布了一篇论文，描述了一种类似的模型，可以从歌曲的文字描述中创建音乐。它的母公司 Alphabet 的投资者正在寻找其对 Chatgpt 的回答。据报道，中国的搜索巨头百度计划在 3 月加入聊天机器人。此外，各种公司研究实验室也在竞争人工智能的优势，其中一些是大型科技公司的一部分，一些与他们有关，一些是独立的创业公司。全球各大公司和独立创业公司都在激烈竞争 AI 的优势，而这场竞赛的结果将决定 AI 的时代对于电脑用户的到来以及谁将占领市场。</p>
<br>
<h2 id="视频讲解">视频讲解</h2>
<iframe
    src="//player.bilibili.com/player.html?bvid=BV1Dv4y1t7FR&page=1"
    scrolling="no"
    height="500px"
    width="800px"
    frameborder="no"
    framespacing="0"
    allowfullscreen="true"
>
</iframe>

<p><br><br></p>
<h2 id="原文">原文</h2>
<p>以下是 <strong>原文</strong> 以及 <strong>雅思词汇解析</strong> ：</p>
<p>Every so often a technology captures the world’s imagination. The latest example, judging by the chatter in Silicon Valley, on Wall Street, in corner offices, newsrooms and classrooms around the world, is <a href="https://www.economist.com/business/2022/12/08/how-good-is-chatgpt">Chatgpt</a>. In five days after its unveiling in November the artificially intelligent chatbot, created by a startup called Openai, drew 1m users, making it one of the fastest consumer-product launches in history. <a href="https://www.economist.com/business/2023/01/25/how-will-satya-nadella-handle-microsofts-chatgpt-moment">Microsoft</a>, which has just invested $10bn in Openai, wants Chatgpt-like powers, which include generating text, images and video that seem like they could have been created by humans, to infuse much of the software it sells. On January 26th Google published a paper describing a similar model that can create music from a text description of a song. Investors in Alphabet, its parent company, are listening out for its answer to Chatgpt. Baidu, a Chinese search giant, reportedly plans to add a chatbot to its search engine in March.</p>
<p><img loading="lazy" src="https://www.economist.com/img/b/608/883/90/media-assets/image/20230204_WBC930.png" alt="img"  />
</p>
<p>It is too early to say how much of the <a href="https://www.economist.com/business/2022/12/06/artificial-intelligence-is-permeating-business-at-last">early hype</a> is justified. Regardless of the extent to which the “generative” ai models behind Chatgpt and its rivals transform business, culture and society, however, they are already transforming how the tech industry thinks about innovation and its engines—the corporate research labs that, like Openai and Google Research, are combining big tech’s processing power with the brain power of some of computer science’s brightest sparks. These rival labs—be they part of big tech firms, affiliated with them or run by independent startups—are engaged in an epic race for ai supremacy (see chart 1). The result of that race will determine how quickly the age of ai will dawn for computer users everywhere—and who will dominate it.</p>
<p>Corporate research-and-development (r&amp;d) organisations have long been a source of scientific advances, especially in America. A century and a half ago Thomas Edison used the proceeds from his inventions, including the phonograph and the lightbulb, to bankroll his workshop in Menlo Park, New Jersey. After the second world war, America Inc invested heavily in basic science in the hope that this would yield practical products. DuPont (a maker of chemicals), ibm and Xerox (which both manufactured hardware) all housed big research laboratories. at&amp;t’s Bell Labs produced, among other inventions, the transistor, laser and the photovoltaic cell, earning its researchers nine Nobel prizes.</p>
<p>In the late 20th century, though, corporate r&amp;d became steadily less about the r than the d. In 2017 Ashish Arora, an economist, and colleagues examined the period from 1980 to 2006 and found that firms had moved away from basic science towards developing existing ideas. The reason, Mr Arora and his co-authors argued, was the rising cost of research and the increasing difficulty of capturing its fruits. Xerox developed the icons and windows now familiar to computer-users but it was Apple and Microsoft that made most of the money from it. Science remained important to innovation, but it became the dominion of not-for-profit universities.</p>
<p>The rise of ai is shaking things up once again. Big corporations are not the only game in town. Startups such as Anthropic and Character ai have built their own Chatgpt challengers. Stability ai, a startup that has assembled a consortium of small firms, universities and non-profits to pool computing resources, has created a popular open-source model that converts text to images. In China, government-backed outfits such as the Beijing Academy of Artificial Intelligence (baai) are pre-eminent.</p>
<p><img loading="lazy" src="https://www.economist.com/img/b/608/1430/90/media-assets/image/20230204_WBC567.png" alt="img"  />
</p>
<p>But almost all recent breakthroughs in big ai globally have come from giant companies, because they have the computing power (see chart 2), and because this is a rare area where results of basic research can be rapidly incorporated into products. Amazon, whose ai powers its Alexa voice assistant, and Meta, which made waves recently when one of its models beat human players at “Diplomacy”, a strategy board game, respectively produce two-thirds and four-fifths as much ai research as Stanford University, a bastion of computer-science eggheads. Alphabet and Microsoft churn out considerably more, and that is not including <a href="https://www.economist.com/1843/2019/03/01/deepmind-and-google-the-battle-to-control-artificial-intelligence">DeepMind</a>, Google Research’s sister lab which the parent company acquired in 2014, and the Microsoft-affiliated Openai (see chart 3).</p>
<p>Expert opinion varies on who is actually ahead on the merits. The Chinese labs, for example, appear to have a big lead in the subdiscipline of computer vision, which involves analysing images, where they are responsible for the largest share of the most highly cited papers. According to a ranking devised by Microsoft, the top five computer-vision teams in the world are <a href="https://www.economist.com/briefing/2022/10/13/china-and-the-west-are-in-a-race-to-foster-innovation">all Chinese</a>. The baai has also built what it says is the world’s biggest natural-language model, Wu Dao 2.0. Meta’s “Diplomacy” player, Cicero, gets kudos for its use of strategic reasoning and deception against human opponents. DeepMind’s models have beat human champions at Go, a notoriously difficult board game, and can predict the shape of proteins, a long-standing challenge in the life sciences.</p>
<p>Jaw-dropping feats, all. When it comes to the sort of ai that is all the rage thanks to Chatgpt, though, the big battle is between Microsoft and Alphabet. To see whose tech is superior, <em>The Economist</em> has put both firms’ ais through their paces. With the help of an engineer at Google, we asked Chatgpt, based on an Openai model called gpt-3.5, and Google’s yet-to-be-launched chatbot, built upon one called Lamda, a set of questions. These included ten problems from an American maths competition (“Find the number of ordered pairs of prime numbers that sum to 60”) and ten reading questions from America’s sat school-leavers’ exam (“Read the passage and determine which choice best describes what happens in it”). To spice things up, we also asked each model for dating advice (“Given the following conversation from a dating app, what is the best way to ask someone out on a first date?”).</p>
<p>Neither ai emerged as clearly superior. Google’s was slightly better at maths, answering five questions correctly, compared with three for Chatgpt. Their dating advice was uneven: fed some real exchanges in a dating app, each gave specific suggestions on one occasion, and platitudes such as “be open minded” and “communicate effectively” on another. Chatgpt, meanwhile, answered nine sat questions correctly compared with seven for its Google rival. It also appeared more responsive to our feedback and got a few questions right on a second try. On January 30th Openai announced an update to Chatgpt improving its maths abilities. When we fed the two ais another ten questions, Lamda again outperformed by two points. But when given a second chance Chatgpt tied.</p>
<p>The reason that, at least so far, no model enjoys an unassailable advantage is that ai knowledge diffuses quickly. Researchers from competing labs “all hang out with each other”, says David Ha of Stability ai. Many, like Mr Ha, who used to work at Google, move between organisations, bringing expertise and experience with them. Moreover, since the best ai brains are scientists at heart, they often made their defection to the private sector conditional on a continued ability to publish their research and present results at conferences. That is partly why Google made public big advances including the “transformer”, a key building block in ai models, giving its rivals a leg-up. (The “t” in Chatgpt stands for transformer.) As a result of all this, reckons Yann LeCun, Meta’s top ai boffin, “Nobody is ahead of anybody else by more than two to six months.”</p>
<p>These are, though, early days. The labs may not remain neck-and-neck for ever. Google has reportedly issued a “code red”, fearing that Chatgpt could boost Microsoft’s rival Bing search engine. Researchers at DeepMind say their firm, which has historically focused on game-playing and science, is putting more resources into language modelling; its chatbot, called Sparrow, may be unveiled this year.</p>
<p>One variable that may help determine the ultimate outcome of the contest is how labs are organised. Openai, a small firm with few revenue streams to protect, may find itself with more latitude than rivals to release products to the public. That in turn is generating tonnes of user data that could make its models better (“reinforcement learning from human feedback”, if you must know)—and thus attract more users.</p>
<p>This early-mover advantage could be self-reinforcing in another way, too. Insiders note that Openai’s rapid progress in recent years has allowed it to poach experts from rivals including DeepMind. To keep up, Alphabet, Amazon and Meta may need to rediscover their ability to move fast and break things—a delicate task given all the regulatory scrutiny they are receiving from governments around the world.</p>
<p>Another deciding factor may be the path of technological development. So far in generative ai, bigger has been better. That has given rich tech giants a huge advantage. But size may not be everything in future. For one thing, there are limits to how big the models can conceivably get. Epoch, a non-profit research institute, estimates that at current rates, big language models will run out of high-quality text on the internet by 2026 (though other less-tapped formats, like video, will remain abundant for a while). More important, as Mr Ha of Stability ai points out, there are ways to fine-tune a model to a specific task that “dramatically reduce the need to scale up”. And novel methods to do more with less are being developed all the time.</p>
<p>The capital flowing into generative-ai startups, which last year collectively raised $2.7bn in 110 deals, suggests that venture capitalists are betting that not all the value will be captured by big tech. Alphabet, Microsoft, their fellow technology titans and the Chinese Communist Party will all try to prove these investors wrong. The ai race is only just getting started.</p>
<br>
<h2 id="雅思词汇解析">雅思词汇解析</h2>
<table>
<thead>
<tr>
<th>雅思词汇</th>
<th>音标</th>
<th>中文释义</th>
<th>真题例句</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>chatter</strong></td>
<td>ˈtʃætər</td>
<td>喧闹的声音，闲聊</td>
<td>The chatter of the students filled the classroom.</td>
</tr>
<tr>
<td><strong>unveil</strong></td>
<td>ʌnˈvel</td>
<td>揭示，公开展示</td>
<td>The company will unveil their new product next week.</td>
</tr>
<tr>
<td><strong>artificially</strong></td>
<td>ɑːtɪˈfɪʃəli</td>
<td>人工的</td>
<td>The flower was made artificially.</td>
</tr>
<tr>
<td><strong>chatbot</strong></td>
<td>ˈtʃætbɑːt</td>
<td>聊天机器人</td>
<td>Many companies are using chatbots to provide customer service.</td>
</tr>
<tr>
<td><strong>startup</strong></td>
<td>ˈstɑːtʌp</td>
<td>创业公司</td>
<td>He invested in a startup that develops new technology.</td>
</tr>
<tr>
<td><strong>infuse</strong></td>
<td>ɪnˈfjuːz</td>
<td>注入，渗入</td>
<td>The tea is infused with a hint of lemon.</td>
</tr>
<tr>
<td><strong>text description</strong></td>
<td>ˈtekst dɪˈskrɪpʃən</td>
<td>文本描述</td>
<td>The text description of the recipe is clear and easy to follow.</td>
</tr>
<tr>
<td><strong>investor</strong></td>
<td>ɪnˈvestər</td>
<td>投资者</td>
<td>The investor is looking for a high return on his investment.</td>
</tr>
<tr>
<td><strong>search giant</strong></td>
<td>sɜːtʃ ˈdʒaɪənt</td>
<td>搜索巨头</td>
<td>Google is one of the biggest search giants in the world.</td>
</tr>
<tr>
<td><strong>hype</strong></td>
<td>haɪp</td>
<td>炒作，宣传</td>
<td>The hype around the new movie was huge.</td>
</tr>
<tr>
<td><strong>justified</strong></td>
<td>ˈdʒʌstɪfaɪd</td>
<td>有理由的，合理的</td>
<td>His anger was justified by the fact that he was mistreated.</td>
</tr>
<tr>
<td><strong>extent</strong></td>
<td>ɪkˈstent</td>
<td>程度，限度</td>
<td>The extent of the damage is still unknown.</td>
</tr>
<tr>
<td><strong>generate</strong></td>
<td>ˈdʒɛnəreɪt</td>
<td>产生，生成</td>
<td>The machine can generate electricity from wind.</td>
</tr>
<tr>
<td><strong>image</strong></td>
<td>ˈɪmɪdʒ</td>
<td>图像</td>
<td>The image of the sun is captured by the satellite.</td>
</tr>
<tr>
<td><strong>epic</strong></td>
<td>ˈɛpɪk</td>
<td>史诗般的，壮丽的</td>
<td>The epic battle lasted for days.</td>
</tr>
<tr>
<td><strong>supremacy</strong></td>
<td>sʊˈprɛməsi</td>
<td>优势，统治地位</td>
<td>The country is striving for military supremacy in the region.</td>
</tr>
<tr>
<td><strong>dawn</strong></td>
<td>dɔːn</td>
<td>黎明，开始</td>
<td>The dawn of a new era has arrived.</td>
</tr>
</tbody>
</table>
<br>
<h2 id="资料获取">资料获取</h2>
<p><a href="%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AE%9E%E9%AA%8C%E5%AE%A4%E7%9A%84%E7%AB%9E%E8%B5%9B%E5%8D%87%E6%B8%A9.pdf">点击下载本文pdf学习资料</a></p>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
